{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "615b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0ec01919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model runs on GPU if it's available\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Save the dataset at this directory\n",
    "DATA_DIR_PATH = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5d832",
   "metadata": {},
   "source": [
    "# Understanding the data\n",
    "I'll be using the MNIST dataset to train the GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f4df4850",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the images are: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# In the MNIST dataset in PyTorch, the pixel values are automatically normalized to the range [0, 1]\n",
    "# The images are first converted to PyTorch Tensors\n",
    "# The data is then re-normalized to be in the range [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# The MNIST dataset is a collection of 70,000 handwritten digits (0-9) with 28x28 pixel resolution images\n",
    "# The above transform will be applied to every image in the dataset\n",
    "mnist_dataset = datasets.MNIST(root=DATA_DIR_PATH, train=True, download=True, transform=transform)\n",
    "\n",
    "# Divides the data into batches of size 'batch_size'\n",
    "mnist_data_loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Consider the first batch of images\n",
    "images, labels = next(iter(mnist_data_loader)) \n",
    "\n",
    "# What's the shape of the images?\n",
    "print(f'The shape of the images are: {images.shape[1:]}')\n",
    "\n",
    "# Visualize the images\n",
    "no_of_images = 16\n",
    "image_subset = images[:no_of_images] # We take only a subset of images to display\n",
    "\n",
    "grid = utils.make_grid(image_subset, nrow=int(np.sqrt(no_of_images)))\n",
    "\n",
    "plt.title('Images from MNIST dataset')\n",
    "plt.imshow(grid.permute(1, 2, 0)) # Matplotlib takes in images with dimensions of form HWC\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498fac0",
   "metadata": {},
   "source": [
    "## Understanding the Components of GANs\n",
    "GANs have two components:\n",
    "1. <b>Generator Network:</b> The generator network takes a random noise vector as input and generates a new image.\n",
    "2. <b>Discriminator Network:</b> The discriminator network takes an image as input and outputs a scalar value indicating whether the image is real or fake.\n",
    "\n",
    "---\n",
    "\n",
    "### How do the two networks work together?\n",
    "> According to Goodfellow et al. (2014), \"The training procedure for Generator model is to maximize the probability of Discriminator making a mistake. This framework corresponds to a <b>minimax two-player game.<b>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7fe21",
   "metadata": {},
   "source": [
    "## Generator Network\n",
    "+ `LeakyReLU` is used as a non-linear activation here.<br>\n",
    "+ `Batch Normalization` is used after each linear layer\n",
    "+ The last layer of the generator network is a `Tanh` function.\n",
    "\n",
    "Learnt some useful insights from https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fde7e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, image_dim):\n",
    "        super().__init__()\n",
    "        num_neurons_per_layer = [256, 512, 1024]\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, num_neurons_per_layer[0]),\n",
    "            nn.BatchNorm1d(num_neurons_per_layer[0]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(num_neurons_per_layer[0], num_neurons_per_layer[1]),\n",
    "            nn.BatchNorm1d(num_neurons_per_layer[1]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(num_neurons_per_layer[1], num_neurons_per_layer[2]),\n",
    "            nn.BatchNorm1d(num_neurons_per_layer[2]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(num_neurons_per_layer[2], image_dim),\n",
    "            nn.Tanh()                       \n",
    "        )\n",
    "        \n",
    "    def forward(self, noise):\n",
    "        out = self.net(noise)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd6c980",
   "metadata": {},
   "source": [
    "## Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "656bbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_dim):\n",
    "        super().__init__()\n",
    "        num_neurons_per_layer = [512, 256, 1]\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(image_dim, num_neurons_per_layer[0]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(num_neurons_per_layer[0], num_neurons_per_layer[1]),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(num_neurons_per_layer[1], num_neurons_per_layer[2]),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        out = net(image)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef04ebe",
   "metadata": {},
   "source": [
    "## Understanding the Training Process\n",
    "\n",
    "I have made the following changes to the original paper:\n",
    "1. The original paper used <b>Momentum</b> but I've used <b>Adam optimizer</b> \n",
    "2. <b>Hyperparameter</b> values are not the same as experiments in the original paper<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Notations used\n",
    "D - Discriminator Network<br>\n",
    "G - Generator network<br>\n",
    "z - random noise<br>\n",
    "x - Image from the data<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Loss Function Intuition\n",
    "<b>Discriminator</b> wants to maximize `log(D(x)) + log(1 - D(G(z)))`<br>\n",
    "<b>Generator</b> wants to minimize the above equation but `X = log(1 - D(G(z)))` part can be considered for minimizing<br>\n",
    "With the above equation, we see vanishing gradients when D performs very well which is why we maximize the equation `log(D(G(z))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "12381680",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# GAN uses Binary Cross Entropy for it's loss function\u001b[39;00m\n\u001b[1;32m      8\u001b[0m adversarial_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m---> 10\u001b[0m discriminator_net \u001b[38;5;241m=\u001b[39m \u001b[43mDiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m generator_net \u001b[38;5;241m=\u001b[39m Generator(noise_dim, image_dim)\u001b[38;5;241m.\u001b[39mtrain()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m discriminator_opt \u001b[38;5;241m=\u001b[39m Adam(discriminator_net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.999\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gans/lib/python3.10/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gans/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gans/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gans/lib/python3.10/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gans/lib/python3.10/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 3e-4\n",
    "num_epochs = 10\n",
    "noise_dim = 28 * 28 * 1\n",
    "image_dim = 28 * 28 * 1 # The dimensions of images in MNIST dataset\n",
    "\n",
    "# GAN uses Binary Cross Entropy for it's loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "discriminator_net = Discriminator(noise_dim).train().to(device)\n",
    "generator_net = Generator(noise_dim, image_dim).train().to(device)\n",
    "\n",
    "discriminator_opt = Adam(discriminator_net.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "generator_opt = Adam(generator_net.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "ones_tensor = torch.ones((batch_size, 1), device=device)\n",
    "zeros_tensor = torch.zeros((batch_size, 1), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f051182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real_images, _) in enumerate(mnist_data_loader):\n",
    "        \n",
    "        #-----------------------------------         \n",
    "        # Training the discriminator network\n",
    "        #-----------------------------------\n",
    "        \n",
    "        real_images = real_images.to(device)\n",
    "        \n",
    "        # PyTorch accumulates gradients over the epochs\n",
    "        # Set the gradients at each step to zero\n",
    "        discriminator_net.zero_grad()\n",
    "        \n",
    "        # To configure the BCELoss to log(D(x)), we pass in a tensor of ones \n",
    "        real_discrminator_loss = adverserial_loss(discriminator_net(real_images), ones_tensor) \n",
    "        \n",
    "        \n",
    "        # create random input noise for the generator\n",
    "        noise = torch.randn(batch_size, noise_dim).to(device)         \n",
    "        fake_images = gen(noise)                                        \n",
    "\n",
    "        # To configure the BCELoss to log(D(G(z))), we pass in a tensor of zeros\n",
    "        fake_image = generator_net(noise)\n",
    "        fake_discriminator_loss = adverserial_loss(discriminator_net(fake_image.detatch()), zeros_tensor)\n",
    "        \n",
    "        discriminator_loss = real_discriminator_loss + fake_discriminator_loss\n",
    "        discriminator_loss.backward()\n",
    "        d_opt\n",
    "        \n",
    "        #-----------------------------------         \n",
    "        # Training the Generator network\n",
    "        #-----------------------------------\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
